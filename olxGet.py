import requests
from bs4 import BeautifulSoup
import datetime
import dataJson
import asyncio
textAds = {}

def olxGetf(url):
    global textAds

    response = requests.get(url, timeout=20)
    try:
        # print(response.status_code)
        response.raise_for_status()  
    except requests.exceptions.RequestException as e:
        print(f"Ð’Ð¸Ð½Ð¸ÐºÐ»Ð° Ð¿Ð¾Ð¼Ð¸Ð»ÐºÐ° Ð¿Ñ–Ð´ Ñ‡Ð°Ñ Ð·Ð°Ð¿Ð¸Ñ‚Ñƒ Ñ‚Ð°Ð¼ Ð´Ðµ ÑÐ¿Ð¸ÑÐ¾Ðº: {e}")
        return ["error", []]  
    soup = BeautifulSoup(response.text, 'lxml')

    card_divs = soup.find_all('div', attrs={'data-cy': 'l-card'})
    
    for card_div in card_divs:
        adsMain = card_div.find('div')
        idAds = card_div.get('id')

        if "Ð¢ÐžÐŸ" in adsMain.text:
            continue
        idsAds = dataJson.get_dataJson()
        if idAds in idsAds:
            if len(idsAds) >= 30:
                idsAds.pop(0)
            return ["SAME", []]
        
        idsAds.append(idAds)
        dataJson.set_dataJson(idsAds)

        p_tags = adsMain.find('div').find_all('div', recursive=False)
        textAll = p_tags[1].find_all('div', recursive=False)
        img_src = card_div.find('img')['src']
        foto_not_found = ""

        if "thumbnail" in img_src:
            img_src = "https://www.completehomerealty.com.au/templates/bt_property/images/avatar-default.jpg"
            print("Ð½ÐµÐ¼Ð°Ñ” Ñ„Ð¾Ñ‚Ð¾")
            foto_not_found = "\nâš <b>Ð½ÐµÐ¼Ð°Ñ” Ñ„Ð¾Ñ‚Ð¾</b>"
        try:
            textAds = {
                'id' : idAds,
                'title' : textAll[0].find("h6").text.replace("\n", " ")+foto_not_found,
                'price' : textAll[0].find("p").text.replace("Ð³Ñ€Ð½.", "").replace(" ", "").replace("Ð”Ð¾Ð³Ð¾Ð²Ñ–Ñ€Ð½Ð°", ""),
                'place' :  textAll[2].find("p").text.split("-")[0],
                'data' :  textAll[2].find("p").text.split("-")[1],
                'dataGet' : str(datetime.datetime.now()),
                'url' : "https://www.olx.ua/"+card_div.find('a')['href'],
                'img' : img_src.replace("s=200x0;q=50", "s=750x1000"),
            }
            
            try:
                response = requests.get(textAds['url'], timeout=10)
                response.raise_for_status()  
            except requests.exceptions.RequestException as e:
                print(f"Ð’Ð¸Ð½Ð¸ÐºÐ»Ð° Ð¿Ð¾Ð¼Ð¸Ð»ÐºÐ° Ð¿Ñ–Ð´ Ñ‡Ð°Ñ Ð·Ð°Ð¿Ð¸Ñ‚Ñƒ Ñ‚Ð°Ð¼ Ð´Ðµ ÑÑ‚Ð¾Ñ€Ñ–Ð½ÐºÐ° Ð¾Ð³Ð¾Ð»Ð¾ÑˆÐµÐ½Ð½Ñ: {e}")
                return ["error", []]  
            soup = BeautifulSoup(response.text, 'lxml')
            
            textAds['description'] = soup.find('div', attrs={'data-cy': 'ad_description'}).text[4:]
            textAds['user_reg'] = soup.find('a', attrs={'data-testid': 'user-profile-link'}).find('div', string=lambda text: text and "Member" in text).text.replace("Member Since", "")
            textAds['user_reg'] = "âœ…"+textAds['user_reg'] if datetime.datetime.now().strftime("%B %Y") != textAds['user_reg'] else "âŒ"+textAds['user_reg']

            if len(textAds['description']) > 600:
                textAds['description'] = textAds['description'][:600]+"...ðŸ”»ðŸ”»ðŸ”»"
        except AttributeError:
            print(textAll)
            continue
        try:
            with open("olxSee.txt", "a", encoding="utf-8") as file:
                file.write("|{:^9}|{:<70}|{:10}|{:10} | {:15}| {:23} | {:120} | {:100} | {}\n".format(
                    textAds['id'], 
                    textAds['title'],
                    textAds['price'], 
                    textAds['data'], 
                    textAds['dataGet'], 
                    textAds['place'], 
                    textAds['url'], 
                    textAds['img'],
                    textAds['description'], 
                    ))
        except Exception as e:
            print(e)
            return ["BAD Ð¿Ð¾Ð¼Ð¸Ð»ÐºÐ° Ð·Ð°Ð¿Ð¸ÑÑƒ Ñƒ Ñ„Ð°Ð¹Ð»", []]
        return ["NEW", textAds]
    return [f"BAD {card_divs=}", []]